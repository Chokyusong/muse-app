from datetime import datetime, timedelta
import sys
import os

# â”€â”€[ì„¤ì •]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEPLOY_DATE = datetime(2025, 9, 1)   # ë°°í¬ì¼
VALID_DAYS  = 40                     # ì‚¬ìš© ê°€ëŠ¥ ê¸°ê°„ (ì¼)
FORCE_EXPIRE = False                 # í…ŒìŠ¤íŠ¸ ê°•ì œ ë§Œë£Œ ìŠ¤ìœ„ì¹˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _should_expire(now: datetime) -> bool:
    if FORCE_EXPIRE:
        return True
    if os.environ.get("TEST_EXPIRE", "").strip() == "1":
        return True
    if any(arg in ("--expire-now", "/expire-now") for arg in sys.argv[1:]):
        return True
    expire_date = DEPLOY_DATE + timedelta(days=VALID_DAYS)
    return now > expire_date

def _block_with_message(msg: str):
    try:
        import tkinter as tk
        from tkinter import messagebox
        root = tk.Tk(); root.withdraw()
        messagebox.showerror("ì‚¬ìš© ê¸°ê°„ ë§Œë£Œ", msg)
    except Exception:
        print(msg)
    finally:
        sys.exit(1)

if _should_expire(datetime.now()):
    _block_with_message("âš ï¸ ì‚¬ìš© ê¸°ê°„ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\nê°œë°œìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")

# -*- coding: utf-8 -*-
"""
desktop_app.py  (v2025-09-01, tag-based rounds)
- PandaLive í•˜íŠ¸ ì§‘ê³„ & ìª½ì§€ ë°œì†¡ (Tkinter)
- ì—‘ì…€ ì´í•©ì‚°: íŒŒì¼ëª… 4ìë¦¬ íƒœê·¸(ì˜ˆ: 0804) ê¸°ì¤€ íšŒì°¨/ìš”ì•½ ìƒì„±
"""

import os, sys, io, re, csv, json, time, threading, subprocess, zipfile, unicodedata
from pathlib import Path
from datetime import datetime
from typing import List, Tuple

import pandas as pd
import numpy as np

import tkinter as tk
from tkinter import (
    Tk, ttk, StringVar, Text, NORMAL, DISABLED, END,
    filedialog, messagebox
)

# ====== helpers ======
def sanitize(name: str) -> str:
    return re.sub(r'[\\/*?:\[\]]', "_", str(name))[:31] or "Sheet"

def visual_len(val) -> int:
    s = str("" if val is None else val)
    w = 0
    for ch in s:
        if unicodedata.east_asian_width(ch) in ("F","W","A") or ord(ch) >= 0x1F300:
            w += 2
        else:
            w += 1
    return w

def _strip_zw(s: str) -> str:
    return re.sub(r"[\u200b-\u200f\u202a-\u202e\u2060-\u206f\ufeff]", "", s)

BRACKET_ANY = r"[()\[\]{}<>ã€Œã€ã€ã€ã€ã€‘ã€ˆã€‰ã€Šã€‹âŸ¦âŸ§â²â³]"

def normalize_nick(nick: str) -> str:
    if not isinstance(nick, str):
        return ""
    s = unicodedata.normalize("NFKC", nick)
    s = _strip_zw(s)
    for _ in range(3):
        s = re.sub(fr"^\s*{BRACKET_ANY}.*?{BRACKET_ANY}\s*", "", s)
        s = re.sub(fr"\s*{BRACKET_ANY}.*?{BRACKET_ANY}\s*$", "", s)
        s = re.sub(fr"{BRACKET_ANY}.*?{BRACKET_ANY}", " ", s)
    s = re.sub(r"[\U0001F000-\U0001FAFF\U00002700-\U000027BF\U00002600-\U000026FF]+", "", s)
    s = re.sub(r"[â¤ï¸â™¡â™¥ï¸ğŸ’—ğŸ’–ğŸ’˜ğŸ’ğŸ’ğŸ’Ÿâœ¨â­ï¸â˜€ï¸]+", "", s)
    s = re.sub(r"\s*(ë‹˜|í˜•|ëˆ„ë‚˜|ì˜¤ë¹ |ì–¸ë‹ˆ)$", "", s)
    s = re.sub(r"[\"'`]+", "", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def normalize_bj(name: str) -> str:
    if not isinstance(name, str):
        return ""
    s = unicodedata.normalize("NFKC", name)
    s = _strip_zw(s)
    s = re.sub(fr"^\s*{BRACKET_ANY}.*?{BRACKET_ANY}\s*", "", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def extract_date_from_name(name: str) -> str:
    s = name.lower()
    m = re.search(r'(20\d{2})[.\-_](\d{1,2})[.\-_](\d{1,2})', s)
    if m: return f"{int(m[1]):04d}-{int(m[2]):02d}-{int(m[3]):02d}"
    m = re.search(r'(20\d{2})(\d{2})(\d{2})', s)
    if m: return f"{int(m[1]):04d}-{int(m[2]):02d}-{int(m[3]):02d}"
    m = re.search(r'(\d{2})[.\-_](\d{1,2})[.\-_](\d{1,2})', s)
    if m: return f"{2000+int(m[1]):04d}-{int(m[2]):02d}-{int(m[3]):02d}"
    m = re.search(r'(\d{1,2})(\d{2})', s)
    if m and len(m.group(0)) == 4:
        y = datetime.now().year
        return f"{y:04d}-{int(m[1]):02d}-{int(m[2]):02d}"
    return datetime.now().strftime("%Y-%m-%d")

def read_any_table(path_or_file, sheet=None) -> pd.DataFrame:
    p = str(path_or_file)
    if p.lower().endswith(".xlsx"):
        return pd.read_excel(path_or_file, sheet_name=(sheet if str(sheet).strip() else 0))
    with open(path_or_file, "rb") as f:
        raw = f.read()
    for enc in ["utf-8-sig","utf-8","cp949","euc-kr"]:
        try:
            text = raw.decode(enc)
            try:
                dialect = csv.Sniffer().sniff(text[:4000], delimiters=[",","\t",";","|"])
                sep = dialect.delimiter
            except Exception:
                sep = ","
            return pd.read_csv(io.StringIO(text), sep=sep)
        except Exception:
            continue
    raise ValueError("CSV ì¸ì½”ë”©/êµ¬ë¶„ì í•´ì„ ì‹¤íŒ¨")

# ===== ê²½ë¡œ ìƒìˆ˜ =====
BASE = Path(__file__).resolve().parent
RECIP_CSV = BASE / "recipients_preview.csv"
MESSAGE_TXT = BASE / "message.txt"
ENV_FILE = BASE / ".env"
STATUS_JSON = BASE / "send_status.json"
SENDER_PY = BASE / "panda_dm_sender.py"
LOG_OUT = BASE / "sender_stdout.log"
LOG_ERR = BASE / "sender_stderr.log"

FULLWIDTH_SPACE = "\u3000"

def now_ts() -> str:
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def load_status(path: Path) -> dict:
    if path.exists():
        try: return json.loads(path.read_text(encoding="utf-8"))
        except: pass
    return {"items": [], "meta": {}}

def save_status(path: Path, data: dict) -> None:
    path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")

# ---------------- í•˜íŠ¸ í•©ê³„ ìœ í‹¸ ----------------
AFFILIATE_GENERAL_SUBSTRS = ["@ka"]   # '@ka' í¬í•¨ ì‹œ ì¼ë°˜í•˜íŠ¸ ì˜ˆì™¸

def classify_heart(id_str) -> str:
    if id_str is None:
        return "ì¼ë°˜í•˜íŠ¸"
    s = str(id_str).strip()
    s = s.replace("ï¼ ", "@").lower()
    if any(sub in s for sub in AFFILIATE_GENERAL_SUBSTRS):
        return "ì¼ë°˜í•˜íŠ¸"
    return "ì œíœ´í•˜íŠ¸" if "@" in s else "ì¼ë°˜í•˜íŠ¸"

def sanitize_name(name: str) -> str:
    return re.sub(r'[\\/*?:\[\]]', "_", str(name))[:31] or "BJ"

def preprocess_single(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = [str(c).strip() for c in df.columns]
    col_bj    = next((c for c in df.columns if c == "ì°¸ì—¬BJ"), None)
    col_heart = next((c for c in df.columns if c == "í›„ì›í•˜íŠ¸"), None)
    col_mix   = next((c for c in df.columns if c == "í›„ì› ì•„ì´ë””(ë‹‰ë„¤ì„)"), None)
    if not (col_bj and col_heart and col_mix):
        raise ValueError("í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: ì°¸ì—¬BJ / í›„ì›í•˜íŠ¸ / í›„ì› ì•„ì´ë””(ë‹‰ë„¤ì„)")

    df[col_bj] = df[col_bj].astype(str).str.strip()
    df[col_heart] = df[col_heart].astype(str).str.replace(",", "", regex=False)
    df[col_heart] = pd.to_numeric(df[col_heart], errors="coerce").fillna(0).astype(int)
    df[col_mix] = df[col_mix].astype(str).str.strip()

    sp = df[col_mix].str.extract(r'^\s*(?P<ID>[^()]+?)(?:\((?P<NICK>.*)\))?\s*$')
    df["ID"] = sp["ID"].fillna("").str.replace("ï¼ ","@",regex=False).str.strip()
    df["ë‹‰ë„¤ì„"] = sp["NICK"].fillna("").apply(normalize_nick)

    base = (
        df.groupby([col_bj, "ID", "ë‹‰ë„¤ì„"], as_index=False)[col_heart]
          .sum()
          .rename(columns={col_bj:"ì°¸ì—¬BJ", col_heart:"í›„ì›í•˜íŠ¸"})
    )
    return base

def make_bj_excel_bytes(bj_name: str, sub_df: pd.DataFrame, admin: bool) -> bytes:
    sub = sub_df.copy()
    # ì˜ˆì™¸íŒ¨í„´ê¹Œì§€ ë°˜ì˜í•œ ì œíœ´íŒë³„
    sub["is_aff"] = sub["ID"].apply(lambda x: classify_heart(x) == "ì œíœ´í•˜íŠ¸")
    gen = sub[~sub["is_aff"]].sort_values("í›„ì›í•˜íŠ¸", ascending=False)[["ID","ë‹‰ë„¤ì„","í›„ì›í•˜íŠ¸"]].copy()
    aff = sub[ sub["is_aff"]].sort_values("í›„ì›í•˜íŠ¸", ascending=False)[["ID","ë‹‰ë„¤ì„","í›„ì›í•˜íŠ¸"]].copy()
    gsum, asum = int(gen["í›„ì›í•˜íŠ¸"].sum()), int(aff["í›„ì›í•˜íŠ¸"].sum())

    from openpyxl import Workbook
    from openpyxl.utils import get_column_letter

    wb = Workbook(); ws = wb.active; ws.title = sanitize_name(bj_name)
    if admin:
        ws.append(["", bj_name, gsum+asum, "", ""])
        ws.append(["ID","ë‹‰ë„¤ì„","í›„ì›í•˜íŠ¸","êµ¬ë¶„","í•©ê³„"])
    else:
        ws.append(["", bj_name, gsum+asum])
        ws.append(["ID","ë‹‰ë„¤ì„","í›„ì›í•˜íŠ¸"])
    if not gen.empty:
        if admin:
            gen2 = gen.copy(); gen2["êµ¬ë¶„"] = ""; gen2["í•©ê³„"] = ""
            rows = gen2.values.tolist(); rows[0][3] = "ì¼ë°˜í•˜íŠ¸"; rows[0][4] = gsum
        else:
            rows = gen.values.tolist()
        for r in rows: ws.append(r)
    if not aff.empty:
        if admin:
            aff2 = aff.copy(); aff2["êµ¬ë¶„"] = ""; aff2["í•©ê³„"] = ""
            rows = aff2.values.tolist(); rows[0][3] = "ì œíœ´í•˜íŠ¸"; rows[0][4] = asum
        else:
            rows = aff.values.tolist()
        for r in rows: ws.append(r)

    for col in ws.columns:
        letter = get_column_letter(col[0].column)
        m = 0
        for cell in col: m = max(m, visual_len(cell.value))
        ws.column_dimensions[letter].width = max(12, min(m+2, 80))
    bio = io.BytesIO(); wb.save(bio); bio.seek(0); return bio.getvalue()

def pack_zip(files: dict[str, bytes]) -> bytes:
    zbio = io.BytesIO()
    with zipfile.ZipFile(zbio, "w", compression=zipfile.ZIP_DEFLATED) as zf:
        for fname, data in files.items():
            zf.writestr(fname, data)
    zbio.seek(0); return zbio.getvalue()

# ---------------- DM ë°œì†¡ (íƒ­2) ìœ í‹¸ ----------------
def guess_columns(df: pd.DataFrame) -> Tuple[str,str,str]:
    cols = [str(c).strip() for c in df.columns]
    id_cands    = ["í›„ì›ì•„ì´ë””","ì•„ì´ë””","ID","id","userId","í›„ì› ì•„ì´ë””","í›„ì› ì•„ì´ë””(ë‹‰ë„¤ì„)"]
    nick_cands  = ["ë‹‰ë„¤ì„","í›„ì›ë‹‰ë„¤ì„","ë‹‰","ë³„ëª…","name","nick"]
    heart_cands = ["í›„ì›í•˜íŠ¸","í•˜íŠ¸","hearts","heart","ì´í•˜íŠ¸","í•˜íŠ¸ìˆ˜"]
    def pick(cands):
        for c in cols:
            if c.replace(" ","") in [x.replace(" ","") for x in cands]:
                return c
        return ""
    id_col = pick(id_cands) or cols[0]
    nick_col = pick(nick_cands) or ""
    heart_col = pick(heart_cands) or cols[-1]
    return id_col, nick_col, heart_col

def normalize_id_from_mix(x: str) -> str:
    if pd.isna(x): return ""
    s = str(x).strip()
    m = re.match(r"^\s*([^()]+)", s)
    return (m.group(1) if m else s).strip()

def normalize_nick_from_mix(x: str) -> str:
    if pd.isna(x): return ""
    s = str(x).strip()
    m = re.search(r"\((.*?)\)", s)
    return (m.group(1).strip() if m else "")

def detect_mixed_id(series: pd.Series, sample: int = 200, threshold: float = 0.3) -> bool:
    try:
        vals = series.dropna().astype(str).head(sample)
        hit = sum(("(" in v and ")" in v and v.find("(") < v.find(")")) for v in vals)
        return (len(vals) > 0) and (hit / len(vals) >= threshold)
    except Exception:
        return False

def prepare_from_csv(df: pd.DataFrame, id_col: str, nick_col: str, heart_col: str, force_mixed: bool):
    tmp = df.copy()
    tmp.columns = [str(c).strip() for c in tmp.columns]
    def _to_int(x):
        s = str(x).strip().replace(",", "")
        try: return int(float(s))
        except: return 0
    series_id = tmp[id_col]
    mixed = force_mixed or detect_mixed_id(series_id)
    if mixed:
        tmp["í›„ì›ì•„ì´ë””"] = series_id.map(normalize_id_from_mix)
        tmp["ë‹‰ë„¤ì„_from_mix"] = series_id.map(normalize_nick_from_mix)
    else:
        tmp["í›„ì›ì•„ì´ë””"] = series_id.astype(str).str.strip()
        tmp["ë‹‰ë„¤ì„_from_mix"] = ""
    tmp["ë‹‰ë„¤ì„_src"] = tmp[nick_col].astype(str).str.strip() if nick_col else ""
    tmp["ë‹‰ë„¤ì„"] = tmp["ë‹‰ë„¤ì„_from_mix"]
    mask_empty = (tmp["ë‹‰ë„¤ì„"].astype(str).str.len() == 0)
    tmp.loc[mask_empty, "ë‹‰ë„¤ì„"] = tmp.loc[mask_empty, "ë‹‰ë„¤ì„_src"]
    tmp["í›„ì›í•˜íŠ¸"] = tmp[heart_col].apply(_to_int)
    agg = (
        tmp.groupby(["í›„ì›ì•„ì´ë””"], as_index=False)
           .agg(ë‹‰ë„¤ì„=("ë‹‰ë„¤ì„","first"), í›„ì›í•˜íŠ¸=("í›„ì›í•˜íŠ¸","sum"))
    )
    auto_df = agg[(agg["í›„ì›í•˜íŠ¸"] >= 1000) & (agg["í›„ì›í•˜íŠ¸"] < 10000)].copy()
    vip_df  = agg[ agg["í›„ì›í•˜íŠ¸"] >= 10000].copy()
    auto_df = auto_df.sort_values(["í›„ì›í•˜íŠ¸","í›„ì›ì•„ì´ë””"], ascending=[False,True]).reset_index(drop=True)
    vip_df  = vip_df.sort_values(["í›„ì›í•˜íŠ¸","í›„ì›ì•„ì´ë””"],  ascending=[False,True]).reset_index(drop=True)
    return auto_df, vip_df

def build_messages_with_endspaces(base_msg: str, n: int) -> List[str]:
    FULLWIDTH_SPACE = "\u3000"
    lines = base_msg.splitlines() or [base_msg]
    L = max(1, len(lines))
    out: List[str] = []
    for i in range(n):
        g = i // 5
        add_line_idx = g % L
        add_spaces = (g // L) + 1
        mutated = []
        for j, ln in enumerate(lines):
            mutated.append(ln + (FULLWIDTH_SPACE*add_spaces) if j==add_line_idx else ln)
        msg = "\n".join(mutated)
        out.append(msg[:500] if len(msg)>500 else msg)
    return out

def save_local_bundle(out_df: pd.DataFrame, base_message: str, panda_id: str, panda_pw: str):
    RECIP_CSV.write_text(out_df.to_csv(index=False), encoding="utf-8")
    MESSAGE_TXT.write_text(base_message, encoding="utf-8")
    if panda_id and panda_pw:
        ENV_FILE.write_text(f"PANDA_ID={panda_id}\nPANDA_PW={panda_pw}\n", encoding="utf-8")

# ---------------- GUI ----------------
class App:
    def copy_vip_to_clipboard(self):
        if self._vip_df_cache.empty:
            messagebox.showwarning("ì•ˆë‚´", "VIP ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        text = "\n".join(self._vip_df_cache["í›„ì›ì•„ì´ë””"].astype(str).tolist())
        self.root.clipboard_clear()
        self.root.clipboard_append(text)
        messagebox.showinfo("ì™„ë£Œ", f"VIP ID {len(self._vip_df_cache)}ëª…ì´ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def export_vip_excel(self):
        if self._vip_df_cache.empty:
            messagebox.showwarning("ì•ˆë‚´", "VIP ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        out = filedialog.asksaveasfilename(defaultextension=".xlsx", initialfile="vip_list.xlsx")
        if not out:
            return
        try:
            cols = [c for c in ["í›„ì›ì•„ì´ë””","ë‹‰ë„¤ì„","í›„ì›í•˜íŠ¸"] if c in self._vip_df_cache.columns]
            self._vip_df_cache[cols].to_excel(out, index=False)
            messagebox.showinfo("ì™„ë£Œ", f"VIP ì—‘ì…€ ì €ì¥: {out}")
        except Exception as e:
            messagebox.showerror("ì˜¤ë¥˜", f"ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨: {e}")

    def __init__(self, root: Tk):
        self.root = root
        root.title("í•˜íŠ¸ í•©ê³„ & ìª½ì§€ ë°œì†¡ (Desktop)  v2025-09-01")
        root.geometry("1200x820")

        nb = ttk.Notebook(root)
        self.tab_sum = ttk.Frame(nb)
        self.tab_dm  = ttk.Frame(nb)
        nb.add(self.tab_sum, text="ğŸ“Š í•˜íŠ¸ í•©ê³„")
        nb.add(self.tab_dm,  text="âœ‰ï¸ ìª½ì§€ ë°œì†¡")
        nb.pack(fill="both", expand=True)

        self.build_tab_sum()
        self.build_tab_dm()
        self.tick()

    # ----- íƒ­1 -----
    def build_tab_sum(self):
        f = self.tab_sum
        frm1 = ttk.LabelFrame(f, text="ë‹¨ì¼ íŒŒì¼ (ê´€ë¦¬ììš©/BJìš© ZIP)")
        frm1.pack(fill="x", padx=10, pady=10)
        self.single_path = StringVar(value="(ì„ íƒ ì—†ìŒ)")
        ttk.Label(frm1, textvariable=self.single_path).pack(anchor="w", padx=10, pady=4)
        ttk.Button(frm1, text="íŒŒì¼ ì„ íƒ (CSV/XLSX)", command=self.pick_single).pack(side="left", padx=10, pady=8)
        ttk.Button(frm1, text="ê´€ë¦¬ììš© ZIP ì €ì¥", command=self.save_admin_zip).pack(side="left", padx=5)
        ttk.Button(frm1, text="BJìš© ZIP ì €ì¥", command=self.save_bj_zip).pack(side="left", padx=5)

        frm2 = ttk.LabelFrame(f, text="ì—¬ëŸ¬ íŒŒì¼ ì´í•©ì‚° ì—‘ì…€")
        frm2.pack(fill="x", padx=10, pady=10)
        self.multi_paths: List[Path] = []
        self.multi_label = StringVar(value="(ì„ íƒ ì—†ìŒ)")
        ttk.Label(frm2, textvariable=self.multi_label).pack(anchor="w", padx=10, pady=4)
        ttk.Button(frm2, text="íŒŒì¼ ì—¬ëŸ¬ ê°œ ì„ íƒ", command=self.pick_multi).pack(side="left", padx=10, pady=8)
        ttk.Button(frm2, text="ì´í•©ì‚° ì—‘ì…€ ì €ì¥", command=self.save_master_excel).pack(side="left", padx=5)

        self.sum_log = Text(f, height=16)
        self.sum_log.pack(fill="both", expand=True, padx=10, pady=10)
        self.log_sum("[ì•ˆë‚´] ë‹¨ì¼ íŒŒì¼ì€ 'ì°¸ì—¬BJ / í›„ì›í•˜íŠ¸ / í›„ì› ì•„ì´ë””(ë‹‰ë„¤ì„)' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        self._single_df = None
        self._admin_zip_bytes = None
        self._bj_zip_bytes = None

    def log_sum(self, msg: str):
        self.sum_log.configure(state=NORMAL); self.sum_log.insert(END, msg.rstrip()+"\n")
        self.sum_log.configure(state=DISABLED); self.sum_log.see(END)

    def pick_single(self):
        path = filedialog.askopenfilename(filetypes=[("CSV/XLSX","*.csv *.xlsx")])
        if not path: return
        self.single_path.set(path)
        try:
            df = read_any_table(Path(path), sheet=None)
            base = preprocess_single(df)
            summary = base.groupby("ì°¸ì—¬BJ", as_index=False)["í›„ì›í•˜íŠ¸"].sum().sort_values("í›„ì›í•˜íŠ¸", ascending=False)

            admin_files, bj_files = {"ìš”ì•½.xlsx": self._to_excel_bytes(summary)}, {"ìš”ì•½.xlsx": self._to_excel_bytes(summary)}
            for bj in summary["ì°¸ì—¬BJ"]:
                sub = base[base["ì°¸ì—¬BJ"] == bj][["ID","ë‹‰ë„¤ì„","í›„ì›í•˜íŠ¸"]]
                admin_files[f"{sanitize_name(str(bj))}.xlsx"] = make_bj_excel_bytes(str(bj), sub, admin=True)
                bj_files[f"{sanitize_name(str(bj))}.xlsx"] = make_bj_excel_bytes(str(bj), sub, admin=False)
            self._admin_zip_bytes = pack_zip(admin_files)
            self._bj_zip_bytes = pack_zip(bj_files)
            self._single_df = base
            self.log_sum(f"[ì™„ë£Œ] ëŒ€ìƒ {len(summary)}ëª… ìš”ì•½ ê³„ì‚°/ZIP ì‘ì„± ì™„ë£Œ.")
        except Exception as e:
            messagebox.showerror("ì˜¤ë¥˜", str(e))

    def _to_excel_bytes(self, df: pd.DataFrame) -> bytes:
        from openpyxl import Workbook
        from openpyxl.utils import get_column_letter
        wb = Workbook(); ws = wb.active; ws.title = "ìš”ì•½"
        ws.append(list(df.columns))
        for _, row in df.iterrows(): ws.append(list(row.values))
        for col in ws.columns:
            letter = get_column_letter(col[0].column)
            m = 0
            for cell in col: m = max(m, visual_len(cell.value))
            ws.column_dimensions[letter].width = max(12, min(m+2, 80))
        bio = io.BytesIO(); wb.save(bio); bio.seek(0); return bio.getvalue()

    def save_admin_zip(self):
        if not self._admin_zip_bytes:
            messagebox.showwarning("ì•ˆë‚´", "ë¨¼ì € ë‹¨ì¼ íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”."); return
        out = filedialog.asksaveasfilename(defaultextension=".zip", initialfile="BJë³„_ê´€ë¦¬ììš©.zip")
        if out: Path(out).write_bytes(self._admin_zip_bytes); self.log_sum(f"[ì €ì¥] {out}")

    def save_bj_zip(self):
        if not self._bj_zip_bytes:
            messagebox.showwarning("ì•ˆë‚´", "ë¨¼ì € ë‹¨ì¼ íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”."); return
        out = filedialog.asksaveasfilename(defaultextension=".zip", initialfile="BJë³„_BJìš©.zip")
        if out: Path(out).write_bytes(self._bj_zip_bytes); self.log_sum(f"[ì €ì¥] {out}")

    def pick_multi(self):
        paths = filedialog.askopenfilenames(filetypes=[("CSV/XLSX","*.csv *.xlsx")])
        if not paths: return
        self.multi_paths = [Path(p) for p in paths]
        names = "; ".join([Path(p).name for p in paths])
        self.multi_label.set((names[:120] + ("..." if len(names)>120 else "")))
        self.log_sum(f"[ì„ íƒ] íŒŒì¼ {len(paths)}ê°œ")

    def save_master_excel(self, *_ev):
        import time
        from openpyxl import Workbook
        from openpyxl.utils import get_column_letter
        
        # === íšŒì°¨ ì¸ë±ìŠ¤ ë§¤í•‘ ì¤€ë¹„ ===
        round_info = []
        seen = set()
        for p in self.multi_paths:
            fn = Path(p).name
            ds = extract_date_from_name(fn)  # YYYY-MM-DD
            if ds in seen:
                continue
            seen.add(ds)

            m4 = re.search(r'(\d{4})', fn)
            if m4:
                tag = m4.group(1)  # ì˜ˆ: '0804'
            else:
                tag = ds[5:].replace('-', '')  # MMDD

            try:
                sort_key = int(tag)
            except:
                sort_key = int(ds.replace('-', ''))  # YYYYMMDD fallback
                tag = ds[5:].replace('-', '')

            round_info.append((sort_key, ds, tag))

        round_info.sort(key=lambda x: x[0])
        date_to_round = {ds: i+1 for i, (_, ds, _) in enumerate(round_info)}
        date_to_tag   = {ds: tag for _, ds, tag in round_info}

        # ì¬ì§„ì… ê°€ë“œ/ë””ë°”ìš´ìŠ¤
        if getattr(self, "_saving_master", False):
            return
        now = time.time()
        if now - getattr(self, "_last_save_master_ts", 0) < 0.8:
            return
        self._saving_master = True

        def _cleanup():
            self._saving_master = False
            self._last_save_master_ts = time.time()

        def _auto_width(ws):
            for col in ws.columns:
                letter = get_column_letter(col[0].column)
                m = 0
                for cell in col:
                    v = "" if cell.value is None else str(cell.value)
                    m = max(m, visual_len(v))
                ws.column_dimensions[letter].width = max(12, min(m + 2, 80))

        def _unique_sheet_name(base: str, used: set[str]) -> str:
            base = sanitize(str(base))[:31] or "Sheet"
            name = base
            i = 2
            while name in used:
                suf = f" ({i})"
                name = base[:31 - len(suf)] + suf
                i += 1
            used.add(name)
            return name

        try:
            if not getattr(self, "multi_paths", None):
                messagebox.showwarning("ì•ˆë‚´", "ë¨¼ì € 'íŒŒì¼ ì—¬ëŸ¬ ê°œ ì„ íƒ'ìœ¼ë¡œ CSV/XLSX íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.")
                _cleanup(); return

            # 1) íŒŒì¼ ì½ê¸° + ì „ì²˜ë¦¬ + íŒŒì¼ëª… íƒœê·¸ ë¶€ì—¬
            self._seen_tags = []  # ìµœì´ˆ ë“±ì¥ ìˆœì„œ ì²´í¬ìš©(ì •ë ¬ì€ ì•„ë˜ì—ì„œ ìˆ«ì ì˜¤ë¦„ì°¨ìˆœ)
            all_rows, err_files = [], []
            for p in self.multi_paths:
                p = Path(p)
                try:
                    # íŒŒì¼ëª…ì—ì„œ 4ìë¦¬ íƒœê·¸ ì¶”ì¶œ(ì—†ìœ¼ë©´ MMDD ë³´ì •)
                    m4 = re.search(r'(\d{4})', p.name)
                    if m4:
                        tag = m4.group(1)  # ì˜ˆ: '0804'
                    else:
                        tag = extract_date_from_name(p.name)[5:].replace('-', '')  # 'MMDD'

                    if tag not in self._seen_tags:
                        self._seen_tags.append(tag)

                    df_in = read_any_table(p, sheet=None)

                    mix_col = "í›„ì› ì•„ì´ë””(ë‹‰ë„¤ì„)"
                    if mix_col not in df_in.columns:
                        raise ValueError(f"{p.name}: '{mix_col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

                    sp = df_in[mix_col].astype(str).str.extract(
                        r'^\s*(?P<ID>[^()]+?)(?:\((?P<NICK>.*)\))?\s*$'
                    )
                    df_in["ID"] = sp["ID"].fillna("").str.replace("ï¼ ", "@", regex=False).str.strip()
                    df_in["ë‹‰ë„¤ì„"] = sp["NICK"].fillna("").apply(normalize_nick)
                    if "ì°¸ì—¬BJ" in df_in.columns:
                        df_in["ì°¸ì—¬BJ"] = df_in["ì°¸ì—¬BJ"].astype(str).apply(normalize_bj)

                    # ì œíœ´/ì¼ë°˜ êµ¬ë¶„ (ì˜ˆì™¸ í¬í•¨)
                    df_in["êµ¬ë¶„"] = df_in["ID"].apply(classify_heart)

                    # í•˜íŠ¸ ì •ìˆ˜í™”
                    if "í›„ì›í•˜íŠ¸" in df_in.columns:
                        df_in["í›„ì›í•˜íŠ¸"] = (
                            df_in["í›„ì›í•˜íŠ¸"].astype(str).str.replace(",", "", regex=False)
                            .pipe(pd.to_numeric, errors="coerce").fillna(0).astype(int)
                        )

                    # íŒŒì¼ëª… íƒœê·¸
                    df_in["íšŒì°¨íƒœê·¸"] = tag

                    cols = ["íšŒì°¨íƒœê·¸", "í›„ì›ì‹œê°„", "ì°¸ì—¬BJ", "ID", "ë‹‰ë„¤ì„", "í›„ì›í•˜íŠ¸", "êµ¬ë¶„"]
                    exist_cols = [c for c in cols if c in df_in.columns]
                    all_rows.append(df_in[exist_cols].copy())

                except Exception as e:
                    err_files.append(f"{p.name}: {e}")

            if err_files:
                self.log_sum("[ê²½ê³ ] ì¼ë¶€ íŒŒì¼ì„ ê±´ë„ˆëœ€:\n  - " + "\n  - ".join(err_files))
            if not all_rows:
                messagebox.showerror("ì˜¤ë¥˜", "ì²˜ë¦¬ ê°€ëŠ¥í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                _cleanup(); return

            merged = pd.concat(all_rows, ignore_index=True)

            # ì•ˆì „ë§ ì •ê·œí™”
            if "ë‹‰ë„¤ì„" in merged.columns:
                merged["ë‹‰ë„¤ì„"] = merged["ë‹‰ë„¤ì„"].apply(normalize_nick)
            if "ì°¸ì—¬BJ" in merged.columns:
                merged["ì°¸ì—¬BJ"] = merged["ì°¸ì—¬BJ"].apply(normalize_bj)

            # 2) íšŒì°¨ë²ˆí˜¸ ë§¤í•‘ (íƒœê·¸ ìˆ«ì ì˜¤ë¦„ì°¨ìˆœ)
            tags_sorted = sorted(getattr(self, "_seen_tags", []), key=lambda x: int(x))
            tag_to_round = {tag: i + 1 for i, tag in enumerate(tags_sorted)}

            # 3) ìš”ì•½_ì¼ë³„ (íŒŒì¼ëª… íƒœê·¸ ê¸°ì¤€)
            need = {"íšŒì°¨íƒœê·¸", "ì°¸ì—¬BJ", "êµ¬ë¶„", "í›„ì›í•˜íŠ¸"}
            if not need.issubset(set(merged.columns)):
                messagebox.showerror("ì˜¤ë¥˜", "í•„ìˆ˜ ì»¬ëŸ¼(íšŒì°¨íƒœê·¸/ì°¸ì—¬BJ/êµ¬ë¶„/í›„ì›í•˜íŠ¸) ë¶€ì¡±ìœ¼ë¡œ ìš”ì•½ì„ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                _cleanup(); return

            piv = (
                merged.groupby(["íšŒì°¨íƒœê·¸", "ì°¸ì—¬BJ", "êµ¬ë¶„"], as_index=False)["í›„ì›í•˜íŠ¸"].sum()
                      .pivot(index=["íšŒì°¨íƒœê·¸", "ì°¸ì—¬BJ"], columns="êµ¬ë¶„", values="í›„ì›í•˜íŠ¸")
                      .fillna(0)
                      .reset_index()
            )
            for col in ["ì¼ë°˜í•˜íŠ¸", "ì œíœ´í•˜íŠ¸"]:
                if col not in piv.columns:
                    piv[col] = 0
            piv["ì´í•©"] = piv["ì¼ë°˜í•˜íŠ¸"] + piv["ì œíœ´í•˜íŠ¸"]
            piv["íšŒì°¨"] = piv["íšŒì°¨íƒœê·¸"].map(tag_to_round).fillna(0).astype(int)
            piv = piv[piv["íšŒì°¨"] > 0].sort_values(["íšŒì°¨", "ì°¸ì—¬BJ"]).reset_index(drop=True)

            df_daily = piv[["íšŒì°¨", "íšŒì°¨íƒœê·¸", "ì°¸ì—¬BJ", "ì¼ë°˜í•˜íŠ¸", "ì œíœ´í•˜íŠ¸", "ì´í•©"]].rename(columns={"íšŒì°¨íƒœê·¸": "íƒœê·¸"})
            df_daily["íšŒì°¨"] = df_daily["íšŒì°¨"].astype(str) + "íšŒì°¨"

            # 4) ìš”ì•½_ì°¸ì—¬BJ_ì´ê³„
            merged["ì°¸ì—¬BJ_ì •ê·œí™”"] = merged["ì°¸ì—¬BJ"].apply(normalize_bj)
            total_by_bj = (
                merged.groupby(["ì°¸ì—¬BJ_ì •ê·œí™”", "êµ¬ë¶„"], as_index=False)["í›„ì›í•˜íŠ¸"].sum()
                      .pivot(index="ì°¸ì—¬BJ_ì •ê·œí™”", columns="êµ¬ë¶„", values="í›„ì›í•˜íŠ¸")
                      .fillna(0)
                      .reset_index()
                      .rename(columns={"ì°¸ì—¬BJ_ì •ê·œí™”": "ì°¸ì—¬BJ"})
            )
            for col in ["ì¼ë°˜í•˜íŠ¸", "ì œíœ´í•˜íŠ¸"]:
                if col not in total_by_bj.columns:
                    total_by_bj[col] = 0
            total_by_bj["ì´í•©"] = total_by_bj["ì¼ë°˜í•˜íŠ¸"] + total_by_bj["ì œíœ´í•˜íŠ¸"]
            df_total = total_by_bj[["ì°¸ì—¬BJ", "ì¼ë°˜í•˜íŠ¸", "ì œíœ´í•˜íŠ¸", "ì´í•©"]].copy()

            # 5) ì €ì¥ ê²½ë¡œ
            # ì²« íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ë¬¸ìì—´ë§Œ í™œìš©í•´ ê¸°ë³¸ íŒŒì¼ëª… êµ¬ì„± (ì‹¤ì œ ì§‘ê³„ëŠ” íƒœê·¸ ê¸°ì¤€)
            default_name = f"ì´í•©ì‚°_{extract_date_from_name(Path(self.multi_paths[0]).name)}.xlsx"
            out = filedialog.asksaveasfilename(defaultextension=".xlsx", initialfile=default_name)
            if not out:
                _cleanup(); return

            # 6) ì—‘ì…€ ì‘ì„±
            wb = Workbook()

            # (A) ìš”ì•½_ì¼ë³„
            ws_daily = wb.active; ws_daily.title = "ìš”ì•½_ì¼ë³„"
            ws_daily.append(list(df_daily.columns))
            for row in df_daily.itertuples(index=False):
                ws_daily.append(list(row))
            _auto_width(ws_daily)

            # (B) ìš”ì•½_ì°¸ì—¬BJ_ì´ê³„
            ws_total = wb.create_sheet(title="ìš”ì•½_ì°¸ì—¬BJ_ì´ê³„")
            ws_total.append(list(df_total.columns))
            for row in df_total.sort_values("ì´í•©", ascending=False).itertuples(index=False):
                ws_total.append(list(row))
            per_round = pd.DataFrame(columns=["íšŒì°¨ë²ˆí˜¸", "í›„ì›í•˜íŠ¸", "íšŒì°¨íƒœê·¸"])  # ì•ˆì „í•œ ê¸°ë³¸ê°’
            if {"íšŒì°¨íƒœê·¸", "í›„ì›í•˜íŠ¸"}.issubset(merged.columns):
                per_round = (
                    merged.groupby("íšŒì°¨íƒœê·¸", as_index=False)["í›„ì›í•˜íŠ¸"].sum()
                )
                per_round["íšŒì°¨ë²ˆí˜¸"] = per_round["íšŒì°¨íƒœê·¸"].map(tag_to_round)
                per_round = per_round.dropna(subset=["íšŒì°¨ë²ˆí˜¸"]).sort_values("íšŒì°¨ë²ˆí˜¸")
                per_round["íšŒì°¨ë²ˆí˜¸"] = per_round["íšŒì°¨ë²ˆí˜¸"].astype(int)

            if not per_round.empty:
                ws_total.append([])
                ws_total.append(["íšŒì°¨ë³„ ì „ì²´ í•©ê³„"])
                ws_total.append(["íšŒì°¨ë²ˆí˜¸", "í›„ì›í•˜íŠ¸", "íšŒì°¨íƒœê·¸"])
                for r in per_round.to_dict("records"):
                    ws_total.append([r["íšŒì°¨ë²ˆí˜¸"], int(r["í›„ì›í•˜íŠ¸"]), r["íšŒì°¨íƒœê·¸"]])
    
            _auto_width(ws_total)

            # (C) ì°¸ì—¬BJë³„ ìƒì„¸ + íšŒì°¨ë³„ í•©ê³„(íƒœê·¸ ê¸°ì¤€)
            merged_sorted = merged.copy()
            sort_cols = [c for c in ["íšŒì°¨íƒœê·¸", "í›„ì›ì‹œê°„"] if c in merged_sorted.columns]
            if sort_cols:
                merged_sorted = merged_sorted.sort_values(sort_cols)
            merged_sorted["BJ_KEY"] = merged_sorted["ì°¸ì—¬BJ"].apply(normalize_bj)

            used_names = {"ìš”ì•½_ì¼ë³„", "ìš”ì•½_ì°¸ì—¬BJ_ì´ê³„"}
            for bj_key, sub in merged_sorted.groupby("BJ_KEY", dropna=False):
                bj_key = bj_key if isinstance(bj_key, str) and bj_key.strip() else "ë¯¸ì§€ì •BJ"

                gsum = int(sub.loc[sub["êµ¬ë¶„"] == "ì¼ë°˜í•˜íŠ¸", "í›„ì›í•˜íŠ¸"].sum())
                asum = int(sub.loc[sub["êµ¬ë¶„"] == "ì œíœ´í•˜íŠ¸", "í›„ì›í•˜íŠ¸"].sum())
                tsum = gsum + asum

                sheet_title = _unique_sheet_name(bj_key, used_names)
                ws = wb.create_sheet(title=sheet_title)

                ws.append([f"ì´ ì¼ë°˜í•˜íŠ¸={gsum}", f"ì´ ì œíœ´í•˜íŠ¸={asum}", f"ì´í•©={tsum}"])

                cols = ["íšŒì°¨íƒœê·¸", "í›„ì›ì‹œê°„", "ID", "ë‹‰ë„¤ì„", "í›„ì›í•˜íŠ¸", "êµ¬ë¶„"]
                exist_cols = [c for c in cols if c in sub.columns]
                ws.append(exist_cols)
                for row in sub[exist_cols].itertuples(index=False):
                    ws.append(list(row))

                # í•˜ë‹¨: íšŒì°¨ë³„ í•©ê³„ (íŒŒì¼ëª… íƒœê·¸ ê¸°ì¤€)
                if "íšŒì°¨íƒœê·¸" in sub.columns:
                    per_round = sub.groupby("íšŒì°¨íƒœê·¸", as_index=False)["í›„ì›í•˜íŠ¸"].sum()
                    per_round["íšŒì°¨ë²ˆí˜¸"] = per_round["íšŒì°¨íƒœê·¸"].map(tag_to_round).fillna(0).astype(int)
                    per_round = per_round[per_round["íšŒì°¨ë²ˆí˜¸"] > 0].sort_values("íšŒì°¨ë²ˆí˜¸")
                    if not per_round.empty:
                        ws.append([])
                        ws.append(["íšŒì°¨ë³„ í•©ê³„"])
                        ws.append(["íšŒì°¨", "í•˜íŠ¸í•©ê³„", "íšŒì°¨íƒœê·¸"])
                        for _, r in per_round.iterrows():
                            ws.append([f"{int(r['íšŒì°¨ë²ˆí˜¸'])}íšŒì°¨",int(r["í›„ì›í•˜íŠ¸"]),str(r["íšŒì°¨íƒœê·¸"])])

                _auto_width(ws)

            wb.save(out)
            self.log_sum(f"[ì €ì¥] ì´í•©ì‚° ì—‘ì…€ ì €ì¥: {out}")
            messagebox.showinfo("ì™„ë£Œ", f"ì´í•©ì‚° ì—‘ì…€ ì €ì¥ ì™„ë£Œ:\n{out}")

        except PermissionError:
            messagebox.showerror("ì €ì¥ ì‹¤íŒ¨", "ì—‘ì…€ì—ì„œ í•´ë‹¹ íŒŒì¼ì´ ì—´ë ¤ìˆìŠµë‹ˆë‹¤.\níŒŒì¼ì„ ë‹«ê³  ë‹¤ì‹œ ì €ì¥í•˜ì„¸ìš”.")
        except Exception as e:
            messagebox.showerror("ì €ì¥ ì‹¤íŒ¨", f"ì—‘ì…€ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n{e}")
        finally:
            _cleanup()

    # ----- íƒ­2 (ìª½ì§€ ì „ì†¡: ê¸°ì¡´ ê·¸ëŒ€ë¡œ) -----
    def build_tab_dm(self):
        f = self.tab_dm

        frm_top = ttk.Frame(f); frm_top.pack(fill="x", padx=10, pady=8)
        left = ttk.Frame(frm_top); right = ttk.Frame(frm_top)
        left.pack(side="left", fill="both", expand=True)
        right.pack(side="left", fill="both", expand=True, padx=(10,0))

        ttk.Label(left, text="íŒ¬ë” ì•„ì´ë””").pack(anchor="w")
        self.var_pid = StringVar(value=""); ttk.Entry(left, textvariable=self.var_pid).pack(fill="x", pady=2)
        ttk.Label(left, text="íŒ¬ë” ë¹„ë°€ë²ˆí˜¸").pack(anchor="w")
        self.var_ppw = StringVar(value=""); ttk.Entry(left, textvariable=self.var_ppw, show="*").pack(fill="x", pady=2)
        ttk.Label(left, text="ê¸°ë³¸ ìª½ì§€ (ì—¬ëŸ¬ ì¤„)").pack(anchor="w", pady=(6,0))
        self.txt_msg = Text(left, height=8); self.txt_msg.pack(fill="both", expand=True, pady=2)

        ttk.Label(right, text="ì›ë³¸ CSV ì—…ë¡œë“œ").pack(anchor="w")
        ttk.Button(right, text="CSV ì„ íƒ", command=self.pick_recip_csv).pack(anchor="w", pady=2)
        ttk.Label(right, text="ìˆ˜ë™ ID ì…ë ¥(ì¤„ë°”ê¿ˆ/ì‰¼í‘œ/ê³µë°±)").pack(anchor="w", pady=(6,0))
        self.txt_manual = Text(right, height=6); self.txt_manual.pack(fill="both", expand=True, pady=2)

        frm_mid = ttk.Frame(f); frm_mid.pack(fill="x", padx=10, pady=8)
        ttk.Button(frm_mid, text="ğŸ’¾ íŒŒì¼ ì €ì¥(.env/CSV/MSG)", command=self.save_bundle).pack(side="left", padx=2)
        ttk.Button(frm_mid, text="ë©”ì‹œì§€ ë³€í˜• ë¯¸ë¦¬ë³´ê¸°", command=self.preview_messages).pack(side="left", padx=2)

        self.lbl_counts = StringVar(value="ìë™ë°œì†¡ ëŒ€ìƒ: 0ëª… | VIP: 0ëª…")
        ttk.Label(f, textvariable=self.lbl_counts).pack(anchor="w", padx=12, pady=(0,4))

        frm_lists = ttk.Frame(f); frm_lists.pack(fill="x", padx=10, pady=4)
        left_list = ttk.LabelFrame(frm_lists, text="ìë™ë°œì†¡ ëŒ€ìƒ (1,000~9,999)")
        right_list = ttk.LabelFrame(frm_lists, text="VIP ëŒ€ìƒ (10,000+)")
        left_list.pack(side="left", fill="both", expand=True, padx=(0,5))
        right_list.pack(side="left", fill="both", expand=True, padx=(5,0))

        self.tree_auto = ttk.Treeview(left_list, columns=("id","nick","heart"), show="headings", height=6)
        for c,t in zip(("id","nick","heart"),("í›„ì›ì•„ì´ë””","ë‹‰ë„¤ì„","í•˜íŠ¸")):
            self.tree_auto.heading(c, text=t)
        self.tree_auto.pack(fill="both", expand=True)

        self.tree_vip = ttk.Treeview(right_list, columns=("id","nick","heart"), show="headings", height=6)
        for c,t in zip(("id","nick","heart"),("í›„ì›ì•„ì´ë””","ë‹‰ë„¤ì„","í•˜íŠ¸")):
            self.tree_vip.heading(c, text=t)
        self.tree_vip.pack(fill="both", expand=True)

        vip_btns = ttk.Frame(right_list)
        vip_btns.pack(fill="x", padx=4, pady=4)
        ttk.Button(vip_btns, text="VIP ID ë³µì‚¬", command=self.copy_vip_to_clipboard).pack(side="left", padx=2)
        ttk.Button(vip_btns, text="VIP ì—‘ì…€ ì €ì¥", command=self.export_vip_excel).pack(side="left", padx=2)

        frm_run = ttk.Frame(f); frm_run.pack(fill="x", padx=10, pady=8)
        ttk.Label(frm_run, text="ì‹œì‘ ì¸ë±ìŠ¤").pack(side="left", padx=3)
        self.var_start = StringVar(value="0"); ttk.Entry(frm_run, textvariable=self.var_start, width=6).pack(side="left")
        ttk.Label(frm_run, text="ìµœëŒ€ ì¸ì›(0=ì „ì›)").pack(side="left", padx=3)
        self.var_limit = StringVar(value="0"); ttk.Entry(frm_run, textvariable=self.var_limit, width=6).pack(side="left")
        self.headless = StringVar(value="1"); ttk.Checkbutton(frm_run, text="í—¤ë“œë¦¬ìŠ¤ ì‹¤í–‰", variable=self.headless, onvalue="1", offvalue="0").pack(side="left", padx=10)
        self.reset_status = StringVar(value="0"); ttk.Checkbutton(frm_run, text="í˜„í™© ì´ˆê¸°í™”", variable=self.reset_status, onvalue="1", offvalue="0").pack(side="left", padx=6)
        ttk.Button(frm_run, text="ğŸ“¨ ì „ì†¡ ì‹¤í–‰", command=self.start_sender).pack(side="left", padx=10)
        ttk.Button(frm_run, text="â›” ê°•ì œ ì¢…ë£Œ", command=self.kill_sender).pack(side="right", padx=4)
        ttk.Button(frm_run, text="ğŸ§¹ í˜„í™©/ì„ì‹œ íŒŒì¼ ì‚­ì œ", command=self.cleanup_files).pack(side="right", padx=4)

        frm_dash = ttk.LabelFrame(f, text="ì‹¤ì‹œê°„ í˜„í™© / ë¡œê·¸"); frm_dash.pack(fill="both", expand=True, padx=10, pady=8)
        self.lbl_stats = StringVar(value="ì´ ëŒ€ìƒ: 0 | ì„±ê³µ: 0 | ì‹¤íŒ¨: 0 | ëŒ€ê¸°: 0")
        ttk.Label(frm_dash, textvariable=self.lbl_stats).pack(anchor="w", padx=8, pady=4)
        ttk.Label(frm_dash, text="ìƒíƒœ").pack(anchor="w", padx=8)
        self.log_out = Text(frm_dash, height=10); self.log_out.pack(fill="both", expand=True, padx=8)
        ttk.Label(frm_dash, text="ë¬´ì‹œ").pack(anchor="w", padx=8)
        self.log_err = Text(frm_dash, height=6); self.log_err.pack(fill="both", expand=True, padx=8)

        self.sender_pid = None
        self._auto_df_cache = pd.DataFrame(columns=["í›„ì›ì•„ì´ë””","ë‹‰ë„¤ì„","í›„ì›í•˜íŠ¸"])
        self._vip_df_cache  = pd.DataFrame(columns=["í›„ì›ì•„ì´ë””","ë‹‰ë„¤ì„","í›„ì›í•˜íŠ¸"])

    def _fill_tree(self, tree: ttk.Treeview, rows: list[tuple]):
        for i in tree.get_children(): tree.delete(i)
        for r in rows: tree.insert("", "end", values=r)

    def pick_recip_csv(self):
        path = filedialog.askopenfilename(filetypes=[("CSV","*.csv")])
        if not path: return
        try:
            df = pd.read_csv(path)
        except Exception:
            df = pd.read_csv(path, encoding="utf-8-sig")

        id_col, nick_col, heart_col = guess_columns(df)
        mixed_guess = detect_mixed_id(df[id_col])
        auto_df, vip_df = prepare_from_csv(df, id_col, nick_col, heart_col, force_mixed=mixed_guess)
        self._auto_df_cache = auto_df
        self._vip_df_cache  = vip_df

        self._fill_tree(self.tree_auto, [(r["í›„ì›ì•„ì´ë””"], r.get("ë‹‰ë„¤ì„",""), r["í›„ì›í•˜íŠ¸"]) for _,r in auto_df.head(50).iterrows()])
        self._fill_tree(self.tree_vip,  [(r["í›„ì›ì•„ì´ë””"], r.get("ë‹‰ë„¤ì„",""), r["í›„ì›í•˜íŠ¸"]) for _,r in vip_df.head(50).iterrows()])

        self.lbl_counts.set(f"ìë™ë°œì†¡ ëŒ€ìƒ: {len(auto_df)}ëª… | VIP: {len(vip_df)}ëª…")
        messagebox.showinfo("ì™„ë£Œ", f"ìë™ë°œì†¡ {len(auto_df)}ëª… / VIP {len(vip_df)}ëª… ì¶”ì¶œ ì™„ë£Œ (ë¯¸ë¦¬ë³´ê¸° ìƒìœ„ 50ëª… í‘œì‹œ).")

    def save_bundle(self):
        manual = self.txt_manual.get("1.0", END).strip()
        if manual:
            tokens = [t.strip() for t in re.split(r"[,\s]+", manual) if t.strip()]
            tokens = list(dict.fromkeys(tokens))
            out_df = pd.DataFrame({"í›„ì›ì•„ì´ë””": tokens, "ë‹‰ë„¤ì„": ["" for _ in tokens], "í›„ì›í•˜íŠ¸": [1000 for _ in tokens]})
        else:
            out_df = self._auto_df_cache

        base_message = self.txt_msg.get("1.0", END).rstrip("\n")
        panda_id = self.var_pid.get().strip()
        panda_pw = self.var_ppw.get().strip()

        if out_df.empty:
            messagebox.showwarning("ì•ˆë‚´", "ëŒ€ìƒì ëª©ë¡ì´ ë¹„ì—ˆìŠµë‹ˆë‹¤."); return

        save_local_bundle(out_df, base_message, panda_id, panda_pw)
        messagebox.showinfo("ì™„ë£Œ", f"recipients_preview.csv / message.txt / .env ì €ì¥ ì™„ë£Œ\n(ìë™ë°œì†¡ ëŒ€ìƒ {len(out_df)}ëª…)")
        st_json = {"items":[{"index":int(i),"id":str(r["í›„ì›ì•„ì´ë””"]),"status":"pending","updated":now_ts()} for i,r in out_df.iterrows()],
                   "meta":{"created": now_ts()}}
        save_status(STATUS_JSON, st_json)

    def preview_messages(self):
        manual = self.txt_manual.get("1.0", END).strip()
        if manual:
            tokens = [t.strip() for t in re.split(r"[,\s]+", manual) if t.strip()]
            tokens = list(dict.fromkeys(tokens))
            out_df = pd.DataFrame({"í›„ì›ì•„ì´ë””": tokens, "ë‹‰ë„¤ì„": ["" for _ in tokens], "í›„ì›í•˜íŠ¸": [1000 for _ in tokens]})
        else:
            out_df = self._auto_df_cache

        base_message = self.txt_msg.get("1.0", END).rstrip("\n")
        msgs = build_messages_with_endspaces(base_message, len(out_df))
        sample = "\n\n".join(f"[{i}] {r['í›„ì›ì•„ì´ë””']}\n{msgs[i]}" for i,(_,r) in enumerate(out_df.head(5).iterrows()))
        messagebox.showinfo("ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5ëª…)", sample or "ì—†ìŒ")

    def start_sender(self):
        if not RECIP_CSV.exists() or not MESSAGE_TXT.exists():
            messagebox.showwarning("ì•ˆë‚´", "ë¨¼ì € íŒŒì¼ ì €ì¥(.env/CSV/MSG)ì„ ëˆ„ë¥´ì„¸ìš”.")
            return

        try:
            s = int(self.var_start.get().strip() or "0")
            l = int(self.var_limit.get().strip() or "0")
        except:
            messagebox.showerror("ì˜¤ë¥˜", "ì‹œì‘/ìµœëŒ€ ì¸ì›ì€ ì •ìˆ˜")
            return

        headless = (self.headless.get() == "1")
        reset = (self.reset_status.get() == "1")

        try:
            LOG_OUT.write_text("", encoding="utf-8")
            LOG_ERR.write_text("", encoding="utf-8")
        except:
            pass

        def _run_inside():
            try:
                import panda_dm_sender as sender
                sender.run_from_gui(
                    headless=headless,
                    status_file=str(STATUS_JSON),
                    reset=reset,
                    start=s,
                    limit=l,
                )
            except Exception as e:
                try:
                    with open(LOG_ERR, "a", encoding="utf-8") as f:
                        f.write(f"{now_ts()}  {e}\n")
                except:
                    pass
                messagebox.showerror("ì‹¤í–‰ ì˜¤ë¥˜", f"ì „ì†¡ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜:\n{e}")

        threading.Thread(target=_run_inside, daemon=True).start()
        messagebox.showinfo("ì•ˆë‚´", "ì „ì†¡ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤. í˜„í™©/ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    def kill_sender(self):
        if self.sender_pid:
            try:
                if os.name == "nt": subprocess.run(["taskkill","/PID", str(self.sender_pid), "/F", "/T"])
                else: os.kill(self.sender_pid, 9)
                self.sender_pid = None; messagebox.showinfo("ì™„ë£Œ", "í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
            except Exception as e:
                messagebox.showerror("ì˜¤ë¥˜", f"ì¢…ë£Œ ì‹¤íŒ¨: {e}")
        else:
            messagebox.showinfo("ì•ˆë‚´", "ì‹¤í–‰ ì¤‘ì¸ ì „ì†¡ í”„ë¡œì„¸ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

    def cleanup_files(self):
        for p in [STATUS_JSON, RECIP_CSV, MESSAGE_TXT, ENV_FILE]:
            try: p.unlink(missing_ok=True)
            except: pass
        try: LOG_OUT.unlink(missing_ok=True); LOG_ERR.unlink(missing_ok=True)
        except: pass
        messagebox.showinfo("ì™„ë£Œ", "í˜„í™©/ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")

    def refresh_dashboard(self):
        data = load_status(STATUS_JSON)
        items = data.get("items", [])
        total = len(items)
        succ = sum(1 for x in items if x.get("status")=="success")
        fail = sum(1 for x in items if x.get("status")=="fail")
        pend = total - succ - fail
        self.lbl_stats.set(f"ì´ ëŒ€ìƒ: {total} | ì„±ê³µ: {succ} ğŸŸ¢ | ì‹¤íŒ¨: {fail} ğŸ”´ | ëŒ€ê¸°: {pend} ğŸŸ¡")
        lines = []
        for row in items[-30:]:
            s = row.get("status","pending")
            lamp = "ğŸŸ¢" if s=="success" else ("ğŸ”´" if s=="fail" else "ğŸŸ¡")
            lines.append(f"{lamp}  #{row.get('index')}  {row.get('id')}  {row.get('updated')}")
        table_text = "\n".join(lines) if lines else "(ì§„í–‰ í•­ëª© ì—†ìŒ)"
        def tail_bytes(p: Path, max_chars=12000):
            if not p.exists(): return ""
            try: return p.read_text(encoding="utf-8")[-max_chars:]
            except: return ""
        self._set_text(self.log_out, table_text + "\n\n--- STDOUT ---\n" + tail_bytes(LOG_OUT))
        self._set_text(self.log_err, tail_bytes(LOG_ERR))

    def _set_text(self, widget: Text, content: str):
        widget.configure(state=NORMAL); widget.delete("1.0", END); widget.insert("1.0", content or "(ì—†ìŒ)")
        widget.configure(state=DISABLED); widget.see(END)

    def tick(self):
        try: self.refresh_dashboard()
        except Exception: pass
        self.root.after(1000, self.tick)

# ===== main =====
if __name__ == "__main__":
    root = Tk()
    app = App(root)
    root.mainloop()
